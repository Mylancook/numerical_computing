\lab{Markov Chains}{Markov Chains}
\label{lab:Markov}

% TODO: recommend changing column_sum = 1 to row_sum = 1 (transpose all transition matrices, ij^th entry --> probability of going from from state i to state j (instead of the other way around). Makes implementing everything easier.)

\objective{A \emph{Markov chain} is a finite collection of states with specified probabilities for transitioning from one state to another. They are characterized by the fact that future behavior of the system depends only on its current state. Markov chains have far ranging applications; in this lab, we create a Markov chain for generating random English sentences.}

\section*{Definition and Implementation}

Suppose that we wish to model a system that can be described by a finite number of states.
A Markov chain is a collection of states, together with the probabilities of moving from one state to another.
An example of a Markov chain is a board game where players move around the board based on die rolls.
Each space represents a state, and a player is said to be in a state if their piece is currently on the corresponding space.
In this case, the probability of moving from one space to another only depends on the players current location.
Where the player was on a previous turn does not affect their current turn.

Markov chains have an associated transition matrix that stores all the information about the chain.
The $(ij)^{th}$ entry of the matrix gives the probability of moving from state $j$ to state $i$.
Thus the columns of the transition matrix must sum to 1.

Consider a very simple weather model, where the probability of being hot or cold depends on the weather of the previous day.
If the probability that tomorrow is hot given that today is hot is 0.7, and the probability that tomorrow is cold given that today is cold is 0.4, then by assigning hot to the $0^{th}$ column and cold to the $1^{st}$ column, the Markov chain has the following transition matrix:
\[ W = \left( \begin{array}{cc}
0.7 & 0.6 \\
0.3 & 0.4 \end{array} \right)\] 

We interpret the matrix $W$ as follows.
If it is hot today, examine the $0^{th}$ column of $W$.
There is a $70\%$ chance that tomorrow will be hot ($0^{th}$ row), and a $30\%$ chance that tomorrow will be cold ($1^{st}$ row).
Conversely, if it is cold today, here is a $60\%$ chance that tomorrow will be hot, and a $40\%$ chance that tomorrow will be cold.

\begin{problem}
Transition matrices for Markov chains are efficiently stored as NumPy arrays.
Write a function that accepts a dimension $n$ and returns the transition matrix for a random Markov chain with $n$ states.
\end{problem}

\section*{Simulating State Transitions}

We may simulate moving from state to state by sampling from a uniform distribution.
In a general Markov chain, if we are in state $j$ then the $j^{th}$ column of the transition matrix gives the probabilities of moving to any other state $i$.
By definition, these probabilities sum to $1$.
Thus, the entries of each column partition the interval $[0, 1]$, and we can choose the next state to move to by generating a random number between $0$ and $1$.

Consider again the weather model example from the previous section.
Suppose that today is hot, and that we want to simulate tomorrow's weather.
The column that corresponds to ``hot'' in the transition matrix is $(0.7, 0.3)^T$.
If we generate a random number and it is smaller than $0.3$, then our simulation indicates that tomorrow will be cold.
Conversely, if the random number is betwen $0.3$ and $1$, then the simulation says that tomorrow will be hot.
In Python, the programming logic is as follows:

\begin{lstlisting}
import numpy as np

def forecast():
	"""Forecast tomorrow's weather given that today is hot."""

	transition_matrix = np.array([[0.7, 0.6], [0.3, 0.4]])
	random_number = np.random.random()
	if random_number < transition_matrix[1,0]:
		print "Cold"
		return 1
	else:
		print "Hot"
		return 0
\end{lstlisting}

% Problem 2: Forcasting over several days.
\begin{problem}
Modify the \li{forecast} function so that it accepts a parameter \li{num\_days} and runs a simulation of the weather for the number of days given.
Return a list containing the day-by-day weather predictions (0 for hot, 1 for cold).
Assume the first day is hot, but do not include the data from the first day in the list of predictions.
The resulting list should therefore have \li{num\_days} entries.
\end{problem}

For Markov chains with very few states, the approach in the \li{forecast} function is practical and the implementation is fairly simple.
However, small Markov chains are typically useless in applications.

\subsection*{Larger Chains}

The \li{forecast} function makes one random draw from a \emph{uniform} distribution to simulate a state change.
For larger Markov chains, we draw from a \emph{multinomial} distribution.
A multinomial distribution is a mulitvariate generalization of the binomial distribution.
A single draw from a binomial distribution with parameter $p$ indicates successes or failure of a single experiment with probability $p$ of success.
The classic example is a coin flip, where the $p$ is the probability that the coin lands heads side up.
A single draw from a multinomial distribution with parameters $\left[p_1, p_2, ..., p_n \right]$ indicates which of $n$ outcomes occurs.
In this case the classic example is a dice roll, with $6$ possible outcomes instead of the $2$ in a coin toss.

\begin{lstlisting}
# To simulate a single dice roll, store the probabilities of each outcome.
>>> probabilities = np.array([1./6, 1./6, 1./6, 1./6, 1./6, 1./6])

# Make a single random draw (roll the die once).
>>> np.random.multinomial(1, probabilities)         
array([0, 0, 0, 1, 0, 0])                       # The roll resulted in a 4.
\end{lstlisting}

% Problem 3: 4 states instead of 2. Multinomial transitioning.
\begin{problem}
Let the following be the transition chain for a Markov chain modeling weather with four states: hot, mild, cold, and freezing.

\[ W^\prime = \left( \begin{array}{cccc}
0.5 & 0.3 & 0.1 & 0\\
0.3 & 0.3 & 0.3 & 0.3\\
0.2 & 0.3 & 0.4 & 0.5\\
  0 & 0.1 & 0.2 & 0.2\end{array} \right)\]
with hot, mild, cold, and freezing corresponding to columns 0, 1, 2, and 3, respectively.

Write a new function that accepts a parameter \li{num\_days} and runs the same kind of simulation as \li{forecast}, but that uses the new four-state transition matrix.
This time, assume the first day is mild.
Return a list containing the day-to-day results (0 for hot, 1 for mild, 2 for cold, and 3 for freezing).
\label{problem:transition}
\end{problem}

% Problem 4: Analysis of results.
\begin{problem}
Write a function that investigates and interprets the results of the simulations in the previous two problems.
Specifically, find the average percentage of days that are hot, mild, cold, and freezing in each simulation.
Does changing the starting day alter the results?
Print a report of your findings to the terminal.
\end{problem}

\section*{Using Markov Chains to Simulate English}
% TODO: is it okay to make this reference?
One of the original applications of Markov chains was to study natural languages\footnote{See \url{http://langvillea.people.cofc.edu/MCapps7.pdf} for some details}.
In the early $20^{th}$ century, Markov used his chains to model how Russian switched from vowels to consonants.
By midcentury, they had been used to try and model English.
It turns out that Markov chains are, by themselves, insufficient to model very good English.
However, they can approach a model of bad English, with sometimes amusing results.

A Markov chain model of English has each word as a state.
By nature, a Markov chain is only concerned with its current state.
Thus, a Markov chain is unaware of context or even previous words in a sentence.
For example, a Markov chain's current state may be the word ``continuous.''
Then the chain would say that the next word in the sentence is more likey to be ``function'' rather than ``racoon.''
However, without the context of the rest of the sentence, even two likely words stringed together may result in gibberish.

To build a Markov chain to simulate English, we need to determine the transition probabilities between words.
One way to do this would be to assign every word in English a number.
Say there are $N$ of them, and create an $N\times N$ matrix of zeros.
Then, read every written work in English and when word $b$ follows word $a$, we add 1 to the $(b,a)^{th}$ entry of the matrix.
Once we have done this for every word of every written work, we normalize the columns and have a transition matrix that we may simulate from.

The main problem with this approach is the sheer enormity of the task at hand.
We will restrict ourselves to a subproblem of modeling the English of a specific file.
Thus, the transition probabilities of our Markov chains will reflect the sort of English that the source authors speak.
For example, the transition matrix built from the Complete Works of William Shakespeare will differ greatly from, say, a collection of academic journals.
We will call the source collection of works in the next problems the \emph{training set}.
%Specifically, we will use the posts from the math stack exchange website.
%(See \texttt{stack_exchange_posts.txt}).

% Problem 5: Text file to file of ints.
\begin{problem}
First we must convert a file of English words to numbers.
Each unique word in the file will correspond to a single number, and each of these numbers will correspond to a row and column in the transition matrix (to be built in the next problem).

Write a function that accepts the path to a file containing a training set of English sentences, with one sentence per line.
Parse the file, assigning a unique natural number to each unique word.
As you parse, write the corresponding sequence of numbers to a new file, maintaining the line break structure.

We provide an example below.
On the left is the training set of sentences, and on the right is the corresponding file of numbers.
Note that once a word is assigned a number, the same number is used to represent the word throughout the rest of the file, thus preserving the 1-1 relationship of words to numbers.

\begin{lstlisting}
<<Love is patient Love is kind 						1 2 3 1 2 4 
It does not envy It does not boast 					5 6 7 8 5 6 7 9 
It is not proud It is not rude 						5 2 7 10 5 2 7 11 
It is not self-seeking It is not easily angered  	5 2 7 5 2 7 12 13 14 
It keeps no record of wrongs						5 15 16 17 18 19 
Love does not delight in evil						1 6 7 20 21 22 
but rejoices with the truth 						23 24 25 26 27 
It always protects always trusts 					5 28 29 28 30 
always hopes always perseveres 						28 31 28 32
Love never fails 									1 33 34>>
\end{lstlisting}

Here the word ``Love'' is assigned the number 1, ``is'' is assigned 2, and ``kind'' is assigned 4 (since it is the $4^{th}$ unique word in the file).

Also keep track of each word-number pair with a some basic data structure.
This could be an ordered list of words, a word-number dictionary, a set of tuples, or any other simple structure (which will be fastest?).
Return this data structure.

\begin{comment}
Also return a list that matches the index of the list to the word assigned that number, prepending and appending unique values for the start and stop states.
The list generated by the above example could be:
\begin{lstlisting}
<<[$tart, Love, is, patient, kind, It, does, not, ..., never, fails, en&]>>
\end{lstlisting}

Examine each line, one at a time.
Check each word in the line to see if it has been assigned a number yet.
If it hasn't, then assign the word a number and write the number into a new file.
If a number has been assigned already, write it to the new file.
The line break structure should be maintained.
\end{comment}
\label{problem:str_to_int}
\end{problem}

\subsection*{Starting and Stopping states}

Now that we have converted our English text into numbers, we can build the transition matrix for the Markov chain.
We will scan the file we created in the previous problem and use it to create the matrix.

In the previous weather model we chose a fixed number of states to simulate.
However, in English, sentences are of varying length.
One way to simulate this is to create a start state and an end state.
To generate a new sentence, we begin in the given start state.
The start state may transition to any of the words that are at the beginning of the sentences in the training set.
Words that are at the end of the sentences in the training set will have a probability of moving to the end state.
Once the chain has moved to the end state, we terminate the sentence.

% Problem 6: Generate the Markov chain's transition matrix.
\begin{problem}
Write a function that accepts the path to the file created in the previous problem and the number of unique words in the training.
Initialize a square zero matrix of zeros whose dimension is the number of unique words in the text, plus 2 (to include the start and stop state).
Then, read each line of the file and for each pair of subsequent numbers add one to the corresponding entry of the matrix.

For instance, if we scanned the line 2 6 3 7 9, then we would add one to the $(6,2)$, $(3,6)$, $(7,3)$, and $(9,7)$ entries of the matrix.
In addition, the start state must transition to the first word in of the line and the last word of the line must transition to the end state.
Then we would also increment the $(2,0)$ and $(N,9)$ entries, where $N$ is the index of the last column in the matrix.
Finally, to avoid a column of all zeros, we say that the end state transitions to itself with probability 1.
Thus we increment the $(N,N)$ entry as well.

Once the entire file has been read, divide each column by its column sum.
Then each column will sum to one, with the $ij^{th}$ entry corresponding to the probability of moving from word $j$ to word $i$.
\label{problem:chainmaker}
\end{problem}

%\subsection*{Teaching the Markov Chain}

%Now that we know how to travel through a Markov chain, we will build one to simulate English.

% Problem 7: Random Sentences
\begin{problem}
Write a function that accepts a file name to read data in from (the training set), a file name to write data out to, and an optional integer argument \li{num\_sentences}.
Use Problem \ref{problem:str_to_int} to write the file of numbers that corresponds to the training set, and to get the data structure describing the one-to-one relationship between the words and the numbers.
Then use Problem \ref{problem:chainmaker} to generate the corresponding transition matrix.

Begin at the start state and use the strategy from Problem \ref{problem:transition} to transition through the Markov chain.
Keep track of the path through the chain and the corresponding path of words.
When the end state is reached, stop transitioning and terminate the sentence.
Write the resulting sentence to the outfile, followed by a newline character.
Write as many sentences to the file as is specified by \li{num\_sentences}.
\end{problem}

\section*{Additional Exercises}

\begin{problem}
The approach in the previous three problems begins to fail as the training set grows larger.
For example, a single Shakespearean play may not be large enough to cause memory problems, but the Complete Works of William Shakespeare certainly will.

Consolidate the functions from the previous three problems into a single function.
Then, to accommodate larger data sets, use a sparse matrix for the transition matrix in instead of a regular NumPy array (use the \li{lil_matrix} from the \li{scipy.sparse} library).
Ensure that the process still works on small training sets, then proceed to larger training sets.
How are the resulting sentences different if a very large training set is used instead of a small training set?
\end{problem}
